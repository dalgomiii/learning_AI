{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "\n",
    "    'train' : DataLoader(train_data,\n",
    "                         batch_size = 100,\n",
    "                         shuffle = True,\n",
    "                         num_workers = 1),\n",
    "\n",
    "    'test' : DataLoader(test_data,\n",
    "                         batch_size = 100,\n",
    "                         shuffle = True,\n",
    "                         num_workers = 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x125b98cd0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x125d53750>}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10,20,kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x = x.view(-1,320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x,training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimiser = optim.Adam(model.parameters(),lr = 0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device),target.to(device)\n",
    "        optimiser.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output,target)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch}[{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100.*batch_idx/len(loaders[\"train\"]):.0f}%)] \\t {loss.item():.6f}')\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data,target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output,target).item()\n",
    "            pred = output.argmax(dim = 1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy{correct}/{len(loaders[\"test\"].dataset)}({100.*correct/len(loaders[\"test\"].dataset):.0f}%\\n)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/9j56pcy9201dt_t1pww9k6g80000gn/T/ipykernel_3927/3199859990.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1[0/60000 (0%)] \t 2.302145\n",
      "Train Epoch: 1[2000/60000 (3%)] \t 2.284935\n",
      "Train Epoch: 1[4000/60000 (7%)] \t 2.178335\n",
      "Train Epoch: 1[6000/60000 (10%)] \t 1.942323\n",
      "Train Epoch: 1[8000/60000 (13%)] \t 2.025531\n",
      "Train Epoch: 1[10000/60000 (17%)] \t 1.902502\n",
      "Train Epoch: 1[12000/60000 (20%)] \t 1.796666\n",
      "Train Epoch: 1[14000/60000 (23%)] \t 1.832076\n",
      "Train Epoch: 1[16000/60000 (27%)] \t 1.707885\n",
      "Train Epoch: 1[18000/60000 (30%)] \t 1.822477\n",
      "Train Epoch: 1[20000/60000 (33%)] \t 1.700879\n",
      "Train Epoch: 1[22000/60000 (37%)] \t 1.711403\n",
      "Train Epoch: 1[24000/60000 (40%)] \t 1.767615\n",
      "Train Epoch: 1[26000/60000 (43%)] \t 1.679398\n",
      "Train Epoch: 1[28000/60000 (47%)] \t 1.620232\n",
      "Train Epoch: 1[30000/60000 (50%)] \t 1.669435\n",
      "Train Epoch: 1[32000/60000 (53%)] \t 1.662492\n",
      "Train Epoch: 1[34000/60000 (57%)] \t 1.622432\n",
      "Train Epoch: 1[36000/60000 (60%)] \t 1.733882\n",
      "Train Epoch: 1[38000/60000 (63%)] \t 1.695551\n",
      "Train Epoch: 1[40000/60000 (67%)] \t 1.651671\n",
      "Train Epoch: 1[42000/60000 (70%)] \t 1.683404\n",
      "Train Epoch: 1[44000/60000 (73%)] \t 1.627745\n",
      "Train Epoch: 1[46000/60000 (77%)] \t 1.634250\n",
      "Train Epoch: 1[48000/60000 (80%)] \t 1.694008\n",
      "Train Epoch: 1[50000/60000 (83%)] \t 1.614977\n",
      "Train Epoch: 1[52000/60000 (87%)] \t 1.640216\n",
      "Train Epoch: 1[54000/60000 (90%)] \t 1.666521\n",
      "Train Epoch: 1[56000/60000 (93%)] \t 1.551863\n",
      "Train Epoch: 1[58000/60000 (97%)] \t 1.607900\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy9277/10000(93%\n",
      ")\n",
      "Train Epoch: 2[0/60000 (0%)] \t 1.638316\n",
      "Train Epoch: 2[2000/60000 (3%)] \t 1.589145\n",
      "Train Epoch: 2[4000/60000 (7%)] \t 1.591262\n",
      "Train Epoch: 2[6000/60000 (10%)] \t 1.553641\n",
      "Train Epoch: 2[8000/60000 (13%)] \t 1.613633\n",
      "Train Epoch: 2[10000/60000 (17%)] \t 1.625160\n",
      "Train Epoch: 2[12000/60000 (20%)] \t 1.654552\n",
      "Train Epoch: 2[14000/60000 (23%)] \t 1.619167\n",
      "Train Epoch: 2[16000/60000 (27%)] \t 1.590258\n",
      "Train Epoch: 2[18000/60000 (30%)] \t 1.586134\n",
      "Train Epoch: 2[20000/60000 (33%)] \t 1.604080\n",
      "Train Epoch: 2[22000/60000 (37%)] \t 1.588490\n",
      "Train Epoch: 2[24000/60000 (40%)] \t 1.575046\n",
      "Train Epoch: 2[26000/60000 (43%)] \t 1.607159\n",
      "Train Epoch: 2[28000/60000 (47%)] \t 1.590777\n",
      "Train Epoch: 2[30000/60000 (50%)] \t 1.573436\n",
      "Train Epoch: 2[32000/60000 (53%)] \t 1.584448\n",
      "Train Epoch: 2[34000/60000 (57%)] \t 1.596122\n",
      "Train Epoch: 2[36000/60000 (60%)] \t 1.572616\n",
      "Train Epoch: 2[38000/60000 (63%)] \t 1.608777\n",
      "Train Epoch: 2[40000/60000 (67%)] \t 1.550372\n",
      "Train Epoch: 2[42000/60000 (70%)] \t 1.595268\n",
      "Train Epoch: 2[44000/60000 (73%)] \t 1.645330\n",
      "Train Epoch: 2[46000/60000 (77%)] \t 1.513037\n",
      "Train Epoch: 2[48000/60000 (80%)] \t 1.560099\n",
      "Train Epoch: 2[50000/60000 (83%)] \t 1.600797\n",
      "Train Epoch: 2[52000/60000 (87%)] \t 1.560125\n",
      "Train Epoch: 2[54000/60000 (90%)] \t 1.589375\n",
      "Train Epoch: 2[56000/60000 (93%)] \t 1.620679\n",
      "Train Epoch: 2[58000/60000 (97%)] \t 1.585506\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy9471/10000(95%\n",
      ")\n",
      "Train Epoch: 3[0/60000 (0%)] \t 1.564704\n",
      "Train Epoch: 3[2000/60000 (3%)] \t 1.635113\n",
      "Train Epoch: 3[4000/60000 (7%)] \t 1.555945\n",
      "Train Epoch: 3[6000/60000 (10%)] \t 1.566748\n",
      "Train Epoch: 3[8000/60000 (13%)] \t 1.591500\n",
      "Train Epoch: 3[10000/60000 (17%)] \t 1.577418\n",
      "Train Epoch: 3[12000/60000 (20%)] \t 1.612518\n",
      "Train Epoch: 3[14000/60000 (23%)] \t 1.575340\n",
      "Train Epoch: 3[16000/60000 (27%)] \t 1.580308\n",
      "Train Epoch: 3[18000/60000 (30%)] \t 1.557413\n",
      "Train Epoch: 3[20000/60000 (33%)] \t 1.570679\n",
      "Train Epoch: 3[22000/60000 (37%)] \t 1.532767\n",
      "Train Epoch: 3[24000/60000 (40%)] \t 1.586393\n",
      "Train Epoch: 3[26000/60000 (43%)] \t 1.602838\n",
      "Train Epoch: 3[28000/60000 (47%)] \t 1.676494\n",
      "Train Epoch: 3[30000/60000 (50%)] \t 1.572757\n",
      "Train Epoch: 3[32000/60000 (53%)] \t 1.539962\n",
      "Train Epoch: 3[34000/60000 (57%)] \t 1.536325\n",
      "Train Epoch: 3[36000/60000 (60%)] \t 1.573805\n",
      "Train Epoch: 3[38000/60000 (63%)] \t 1.615658\n",
      "Train Epoch: 3[40000/60000 (67%)] \t 1.604083\n",
      "Train Epoch: 3[42000/60000 (70%)] \t 1.518481\n",
      "Train Epoch: 3[44000/60000 (73%)] \t 1.638658\n",
      "Train Epoch: 3[46000/60000 (77%)] \t 1.549989\n",
      "Train Epoch: 3[48000/60000 (80%)] \t 1.608266\n",
      "Train Epoch: 3[50000/60000 (83%)] \t 1.558536\n",
      "Train Epoch: 3[52000/60000 (87%)] \t 1.592302\n",
      "Train Epoch: 3[54000/60000 (90%)] \t 1.536025\n",
      "Train Epoch: 3[56000/60000 (93%)] \t 1.573445\n",
      "Train Epoch: 3[58000/60000 (97%)] \t 1.563931\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy9549/10000(95%\n",
      ")\n",
      "Train Epoch: 4[0/60000 (0%)] \t 1.548982\n",
      "Train Epoch: 4[2000/60000 (3%)] \t 1.571276\n",
      "Train Epoch: 4[4000/60000 (7%)] \t 1.590740\n",
      "Train Epoch: 4[6000/60000 (10%)] \t 1.553548\n",
      "Train Epoch: 4[8000/60000 (13%)] \t 1.536916\n",
      "Train Epoch: 4[10000/60000 (17%)] \t 1.573954\n",
      "Train Epoch: 4[12000/60000 (20%)] \t 1.526794\n",
      "Train Epoch: 4[14000/60000 (23%)] \t 1.544296\n",
      "Train Epoch: 4[16000/60000 (27%)] \t 1.543811\n",
      "Train Epoch: 4[18000/60000 (30%)] \t 1.549728\n",
      "Train Epoch: 4[20000/60000 (33%)] \t 1.567593\n",
      "Train Epoch: 4[22000/60000 (37%)] \t 1.550245\n",
      "Train Epoch: 4[24000/60000 (40%)] \t 1.563150\n",
      "Train Epoch: 4[26000/60000 (43%)] \t 1.583130\n",
      "Train Epoch: 4[28000/60000 (47%)] \t 1.530975\n",
      "Train Epoch: 4[30000/60000 (50%)] \t 1.516841\n",
      "Train Epoch: 4[32000/60000 (53%)] \t 1.530347\n",
      "Train Epoch: 4[34000/60000 (57%)] \t 1.583577\n",
      "Train Epoch: 4[36000/60000 (60%)] \t 1.594919\n",
      "Train Epoch: 4[38000/60000 (63%)] \t 1.554455\n",
      "Train Epoch: 4[40000/60000 (67%)] \t 1.592978\n",
      "Train Epoch: 4[42000/60000 (70%)] \t 1.610522\n",
      "Train Epoch: 4[44000/60000 (73%)] \t 1.578910\n",
      "Train Epoch: 4[46000/60000 (77%)] \t 1.513536\n",
      "Train Epoch: 4[48000/60000 (80%)] \t 1.573497\n",
      "Train Epoch: 4[50000/60000 (83%)] \t 1.541056\n",
      "Train Epoch: 4[52000/60000 (87%)] \t 1.569176\n",
      "Train Epoch: 4[54000/60000 (90%)] \t 1.583042\n",
      "Train Epoch: 4[56000/60000 (93%)] \t 1.547859\n",
      "Train Epoch: 4[58000/60000 (97%)] \t 1.577960\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy9583/10000(96%\n",
      ")\n",
      "Train Epoch: 5[0/60000 (0%)] \t 1.554887\n",
      "Train Epoch: 5[2000/60000 (3%)] \t 1.530294\n",
      "Train Epoch: 5[4000/60000 (7%)] \t 1.610760\n",
      "Train Epoch: 5[6000/60000 (10%)] \t 1.533037\n",
      "Train Epoch: 5[8000/60000 (13%)] \t 1.559764\n",
      "Train Epoch: 5[10000/60000 (17%)] \t 1.547537\n",
      "Train Epoch: 5[12000/60000 (20%)] \t 1.554034\n",
      "Train Epoch: 5[14000/60000 (23%)] \t 1.522178\n",
      "Train Epoch: 5[16000/60000 (27%)] \t 1.565018\n",
      "Train Epoch: 5[18000/60000 (30%)] \t 1.506090\n",
      "Train Epoch: 5[20000/60000 (33%)] \t 1.540309\n",
      "Train Epoch: 5[22000/60000 (37%)] \t 1.583577\n",
      "Train Epoch: 5[24000/60000 (40%)] \t 1.585488\n",
      "Train Epoch: 5[26000/60000 (43%)] \t 1.588063\n",
      "Train Epoch: 5[28000/60000 (47%)] \t 1.546489\n",
      "Train Epoch: 5[30000/60000 (50%)] \t 1.529781\n",
      "Train Epoch: 5[32000/60000 (53%)] \t 1.560455\n",
      "Train Epoch: 5[34000/60000 (57%)] \t 1.484459\n",
      "Train Epoch: 5[36000/60000 (60%)] \t 1.492315\n",
      "Train Epoch: 5[38000/60000 (63%)] \t 1.585446\n",
      "Train Epoch: 5[40000/60000 (67%)] \t 1.508932\n",
      "Train Epoch: 5[42000/60000 (70%)] \t 1.587934\n",
      "Train Epoch: 5[44000/60000 (73%)] \t 1.550892\n",
      "Train Epoch: 5[46000/60000 (77%)] \t 1.545994\n",
      "Train Epoch: 5[48000/60000 (80%)] \t 1.537067\n",
      "Train Epoch: 5[50000/60000 (83%)] \t 1.507030\n",
      "Train Epoch: 5[52000/60000 (87%)] \t 1.529692\n",
      "Train Epoch: 5[54000/60000 (90%)] \t 1.544445\n",
      "Train Epoch: 5[56000/60000 (93%)] \t 1.495597\n",
      "Train Epoch: 5[58000/60000 (97%)] \t 1.580153\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy9635/10000(96%\n",
      ")\n",
      "Train Epoch: 6[0/60000 (0%)] \t 1.540233\n",
      "Train Epoch: 6[2000/60000 (3%)] \t 1.565203\n",
      "Train Epoch: 6[4000/60000 (7%)] \t 1.560872\n",
      "Train Epoch: 6[6000/60000 (10%)] \t 1.536320\n",
      "Train Epoch: 6[8000/60000 (13%)] \t 1.528848\n",
      "Train Epoch: 6[10000/60000 (17%)] \t 1.552424\n",
      "Train Epoch: 6[12000/60000 (20%)] \t 1.606523\n",
      "Train Epoch: 6[14000/60000 (23%)] \t 1.518305\n",
      "Train Epoch: 6[16000/60000 (27%)] \t 1.556272\n",
      "Train Epoch: 6[18000/60000 (30%)] \t 1.567106\n",
      "Train Epoch: 6[20000/60000 (33%)] \t 1.570666\n",
      "Train Epoch: 6[22000/60000 (37%)] \t 1.558162\n",
      "Train Epoch: 6[24000/60000 (40%)] \t 1.550798\n",
      "Train Epoch: 6[26000/60000 (43%)] \t 1.566379\n",
      "Train Epoch: 6[28000/60000 (47%)] \t 1.527391\n",
      "Train Epoch: 6[30000/60000 (50%)] \t 1.545255\n",
      "Train Epoch: 6[32000/60000 (53%)] \t 1.570282\n",
      "Train Epoch: 6[34000/60000 (57%)] \t 1.528992\n",
      "Train Epoch: 6[36000/60000 (60%)] \t 1.524725\n",
      "Train Epoch: 6[38000/60000 (63%)] \t 1.513268\n",
      "Train Epoch: 6[40000/60000 (67%)] \t 1.530503\n",
      "Train Epoch: 6[42000/60000 (70%)] \t 1.524022\n",
      "Train Epoch: 6[44000/60000 (73%)] \t 1.590232\n",
      "Train Epoch: 6[46000/60000 (77%)] \t 1.503730\n",
      "Train Epoch: 6[48000/60000 (80%)] \t 1.521990\n",
      "Train Epoch: 6[50000/60000 (83%)] \t 1.532403\n",
      "Train Epoch: 6[52000/60000 (87%)] \t 1.578224\n",
      "Train Epoch: 6[54000/60000 (90%)] \t 1.510242\n",
      "Train Epoch: 6[56000/60000 (93%)] \t 1.528398\n",
      "Train Epoch: 6[58000/60000 (97%)] \t 1.541546\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy9672/10000(97%\n",
      ")\n",
      "Train Epoch: 7[0/60000 (0%)] \t 1.534403\n",
      "Train Epoch: 7[2000/60000 (3%)] \t 1.517134\n",
      "Train Epoch: 7[4000/60000 (7%)] \t 1.504611\n",
      "Train Epoch: 7[6000/60000 (10%)] \t 1.584285\n",
      "Train Epoch: 7[8000/60000 (13%)] \t 1.560740\n",
      "Train Epoch: 7[10000/60000 (17%)] \t 1.529196\n",
      "Train Epoch: 7[12000/60000 (20%)] \t 1.561814\n",
      "Train Epoch: 7[14000/60000 (23%)] \t 1.562574\n",
      "Train Epoch: 7[16000/60000 (27%)] \t 1.556317\n",
      "Train Epoch: 7[18000/60000 (30%)] \t 1.510364\n",
      "Train Epoch: 7[20000/60000 (33%)] \t 1.548702\n",
      "Train Epoch: 7[22000/60000 (37%)] \t 1.603578\n",
      "Train Epoch: 7[24000/60000 (40%)] \t 1.525292\n",
      "Train Epoch: 7[26000/60000 (43%)] \t 1.558541\n",
      "Train Epoch: 7[28000/60000 (47%)] \t 1.537693\n",
      "Train Epoch: 7[30000/60000 (50%)] \t 1.551226\n",
      "Train Epoch: 7[32000/60000 (53%)] \t 1.522643\n",
      "Train Epoch: 7[34000/60000 (57%)] \t 1.568662\n",
      "Train Epoch: 7[36000/60000 (60%)] \t 1.545021\n",
      "Train Epoch: 7[38000/60000 (63%)] \t 1.515522\n",
      "Train Epoch: 7[40000/60000 (67%)] \t 1.529467\n",
      "Train Epoch: 7[42000/60000 (70%)] \t 1.504783\n",
      "Train Epoch: 7[44000/60000 (73%)] \t 1.531251\n",
      "Train Epoch: 7[46000/60000 (77%)] \t 1.551053\n",
      "Train Epoch: 7[48000/60000 (80%)] \t 1.550409\n",
      "Train Epoch: 7[50000/60000 (83%)] \t 1.552641\n",
      "Train Epoch: 7[52000/60000 (87%)] \t 1.589427\n",
      "Train Epoch: 7[54000/60000 (90%)] \t 1.602874\n",
      "Train Epoch: 7[56000/60000 (93%)] \t 1.537330\n",
      "Train Epoch: 7[58000/60000 (97%)] \t 1.540538\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy9665/10000(97%\n",
      ")\n",
      "Train Epoch: 8[0/60000 (0%)] \t 1.512576\n",
      "Train Epoch: 8[2000/60000 (3%)] \t 1.506252\n",
      "Train Epoch: 8[4000/60000 (7%)] \t 1.542023\n",
      "Train Epoch: 8[6000/60000 (10%)] \t 1.530055\n",
      "Train Epoch: 8[8000/60000 (13%)] \t 1.532543\n",
      "Train Epoch: 8[10000/60000 (17%)] \t 1.561683\n",
      "Train Epoch: 8[12000/60000 (20%)] \t 1.532329\n",
      "Train Epoch: 8[14000/60000 (23%)] \t 1.576404\n",
      "Train Epoch: 8[16000/60000 (27%)] \t 1.530442\n",
      "Train Epoch: 8[18000/60000 (30%)] \t 1.531533\n",
      "Train Epoch: 8[20000/60000 (33%)] \t 1.561190\n",
      "Train Epoch: 8[22000/60000 (37%)] \t 1.556579\n",
      "Train Epoch: 8[24000/60000 (40%)] \t 1.519762\n",
      "Train Epoch: 8[26000/60000 (43%)] \t 1.519102\n",
      "Train Epoch: 8[28000/60000 (47%)] \t 1.531763\n",
      "Train Epoch: 8[30000/60000 (50%)] \t 1.506026\n",
      "Train Epoch: 8[32000/60000 (53%)] \t 1.520184\n",
      "Train Epoch: 8[34000/60000 (57%)] \t 1.540593\n",
      "Train Epoch: 8[36000/60000 (60%)] \t 1.532834\n",
      "Train Epoch: 8[38000/60000 (63%)] \t 1.578416\n",
      "Train Epoch: 8[40000/60000 (67%)] \t 1.557670\n",
      "Train Epoch: 8[42000/60000 (70%)] \t 1.508730\n",
      "Train Epoch: 8[44000/60000 (73%)] \t 1.508472\n",
      "Train Epoch: 8[46000/60000 (77%)] \t 1.496091\n",
      "Train Epoch: 8[48000/60000 (80%)] \t 1.485809\n",
      "Train Epoch: 8[50000/60000 (83%)] \t 1.544957\n",
      "Train Epoch: 8[52000/60000 (87%)] \t 1.502555\n",
      "Train Epoch: 8[54000/60000 (90%)] \t 1.519130\n",
      "Train Epoch: 8[56000/60000 (93%)] \t 1.507759\n",
      "Train Epoch: 8[58000/60000 (97%)] \t 1.505879\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy9708/10000(97%\n",
      ")\n",
      "Train Epoch: 9[0/60000 (0%)] \t 1.576186\n",
      "Train Epoch: 9[2000/60000 (3%)] \t 1.532831\n",
      "Train Epoch: 9[4000/60000 (7%)] \t 1.511416\n",
      "Train Epoch: 9[6000/60000 (10%)] \t 1.529897\n",
      "Train Epoch: 9[8000/60000 (13%)] \t 1.515274\n",
      "Train Epoch: 9[10000/60000 (17%)] \t 1.505059\n",
      "Train Epoch: 9[12000/60000 (20%)] \t 1.522086\n",
      "Train Epoch: 9[14000/60000 (23%)] \t 1.515912\n",
      "Train Epoch: 9[16000/60000 (27%)] \t 1.530046\n",
      "Train Epoch: 9[18000/60000 (30%)] \t 1.498630\n",
      "Train Epoch: 9[20000/60000 (33%)] \t 1.542276\n",
      "Train Epoch: 9[22000/60000 (37%)] \t 1.578654\n",
      "Train Epoch: 9[24000/60000 (40%)] \t 1.475387\n",
      "Train Epoch: 9[26000/60000 (43%)] \t 1.545073\n",
      "Train Epoch: 9[28000/60000 (47%)] \t 1.519904\n",
      "Train Epoch: 9[30000/60000 (50%)] \t 1.508288\n",
      "Train Epoch: 9[32000/60000 (53%)] \t 1.514598\n",
      "Train Epoch: 9[34000/60000 (57%)] \t 1.542290\n",
      "Train Epoch: 9[36000/60000 (60%)] \t 1.509239\n",
      "Train Epoch: 9[38000/60000 (63%)] \t 1.515355\n",
      "Train Epoch: 9[40000/60000 (67%)] \t 1.526392\n",
      "Train Epoch: 9[42000/60000 (70%)] \t 1.516582\n",
      "Train Epoch: 9[44000/60000 (73%)] \t 1.555345\n",
      "Train Epoch: 9[46000/60000 (77%)] \t 1.516080\n",
      "Train Epoch: 9[48000/60000 (80%)] \t 1.496180\n",
      "Train Epoch: 9[50000/60000 (83%)] \t 1.519857\n",
      "Train Epoch: 9[52000/60000 (87%)] \t 1.536078\n",
      "Train Epoch: 9[54000/60000 (90%)] \t 1.529297\n",
      "Train Epoch: 9[56000/60000 (93%)] \t 1.559206\n",
      "Train Epoch: 9[58000/60000 (97%)] \t 1.552260\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy9709/10000(97%\n",
      ")\n",
      "Train Epoch: 10[0/60000 (0%)] \t 1.528126\n",
      "Train Epoch: 10[2000/60000 (3%)] \t 1.512465\n",
      "Train Epoch: 10[4000/60000 (7%)] \t 1.551355\n",
      "Train Epoch: 10[6000/60000 (10%)] \t 1.551355\n",
      "Train Epoch: 10[8000/60000 (13%)] \t 1.498375\n",
      "Train Epoch: 10[10000/60000 (17%)] \t 1.508847\n",
      "Train Epoch: 10[12000/60000 (20%)] \t 1.553089\n",
      "Train Epoch: 10[14000/60000 (23%)] \t 1.521816\n",
      "Train Epoch: 10[16000/60000 (27%)] \t 1.533569\n",
      "Train Epoch: 10[18000/60000 (30%)] \t 1.527511\n",
      "Train Epoch: 10[20000/60000 (33%)] \t 1.566288\n",
      "Train Epoch: 10[22000/60000 (37%)] \t 1.545267\n",
      "Train Epoch: 10[24000/60000 (40%)] \t 1.556947\n",
      "Train Epoch: 10[26000/60000 (43%)] \t 1.555558\n",
      "Train Epoch: 10[28000/60000 (47%)] \t 1.560438\n",
      "Train Epoch: 10[30000/60000 (50%)] \t 1.525127\n",
      "Train Epoch: 10[32000/60000 (53%)] \t 1.556768\n",
      "Train Epoch: 10[34000/60000 (57%)] \t 1.580041\n",
      "Train Epoch: 10[36000/60000 (60%)] \t 1.533535\n",
      "Train Epoch: 10[38000/60000 (63%)] \t 1.501160\n",
      "Train Epoch: 10[40000/60000 (67%)] \t 1.526512\n",
      "Train Epoch: 10[42000/60000 (70%)] \t 1.557132\n",
      "Train Epoch: 10[44000/60000 (73%)] \t 1.547653\n",
      "Train Epoch: 10[46000/60000 (77%)] \t 1.529066\n",
      "Train Epoch: 10[48000/60000 (80%)] \t 1.511674\n",
      "Train Epoch: 10[50000/60000 (83%)] \t 1.506382\n",
      "Train Epoch: 10[52000/60000 (87%)] \t 1.515312\n",
      "Train Epoch: 10[54000/60000 (90%)] \t 1.537724\n",
      "Train Epoch: 10[56000/60000 (93%)] \t 1.520382\n",
      "Train Epoch: 10[58000/60000 (97%)] \t 1.523988\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy9693/10000(97%\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/9j56pcy9201dt_t1pww9k6g80000gn/T/ipykernel_3927/3199859990.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[3] \n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim=1,keepdim=True).item()\n",
    "\n",
    "print(f'Prediction: {prediction}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image,cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
